import zipfile, os, textwrap, sys

zip_path = "/content/segmentations.zip"
if not os.path.exists(zip_path):
    print("No file found at /mnt/data/segmentations.zip")
else:
    with zipfile.ZipFile(zip_path, 'r') as z:
        file_list = z.namelist()
        print(f"Total files in zip: {len(file_list)}\n")
        # show first 50 entries for preview
        for i, f in enumerate(file_list[:50], 1):
            print(f"{i:3d}. {f}")
        if len(file_list) > 50:
            print(f"... (and {len(file_list)-50} more files)")
        # try to detect common structure
        top_dirs = {}
        for f in file_list:
            parts = f.split('/')
            if len(parts) > 1:
                top_dirs[parts[0]] = top_dirs.get(parts[0], 0) + 1
            else:
                top_dirs[parts[0]] = top_dirs.get(parts[0], 0) + 1
        print("\nTop-level entries and counts:")
        for k, v in top_dirs.items():
            print(f" - {k}: {v} files")

"""
train_cancer_classifiers.py

Pipeline:
- read .nii files from a folder (or zip extracted folder)
- read labels.csv (filename,label). If missing, creates demo labels (random).
- extract middle axial slice, resize to 224x224, normalize
- train a simple CNN (Keras)
- extract features from CNN and train an XGBoost classifier
- evaluate both models and save them
"""

import os
import zipfile
import numpy as np
import pandas as pd
import nibabel as nib
from PIL import Image
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, confusion_matrix
import joblib

# --- deep learning imports
import tensorflow as tf
from tensorflow.keras import layers, models, callbacks
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# --- xgboost
import xgboost as xgb

# ------------ USER CONFIG -------------
DATA_ZIP = "/content/segmentations.zip"   # path to uploaded zip
WORK_DIR = "/mnt/data/segmentations_extracted"
IMG_SIZE = (224, 224)
BATCH_SIZE = 8
EPOCHS = 12
RANDOM_STATE = 42
# --------------------------------------

def ensure_extracted(zip_path, out_dir):
    if not os.path.exists(out_dir):
        os.makedirs(out_dir, exist_ok=True)
        print("Extracting zip...")
        with zipfile.ZipFile(zip_path, 'r') as z:
            z.extractall(out_dir)
        print("Extracted to", out_dir)
    else:
        print("Extraction folder already exists:", out_dir)

def load_middle_slice_2d(nii_path, target_size=IMG_SIZE):
    # Loads a NIfTI file and returns the middle axial slice as a 2D numpy array
    img = nib.load(nii_path)
    arr = img.get_fdata()
    # ensure 3d
    if arr.ndim == 4:
        # if there's a time dimension, take first timepoint
        arr = arr[..., 0]
    z_mid = arr.shape[2] // 2
    slice2d = arr[:, :, z_mid]
    # normalize to 0-255 for convenience
    mn, mx = slice2d.min(), slice2d.max()
    if mx - mn > 0:
        slice2d = (slice2d - mn) / (mx - mn)
    else:
        slice2d = np.zeros_like(slice2d)
    pil = Image.fromarray((slice2d * 255).astype(np.uint8))
    pil = pil.resize(target_size, Image.BILINEAR).convert("L")  # grayscale
    arr2 = np.array(pil).astype("float32") / 255.0
    # convert to 3 channels by stacking if desired
    arr3 = np.stack([arr2, arr2, arr2], axis=-1)  # shape: H,W,3
    return arr3

def build_simple_cnn(input_shape=(224,224,3)):
    inp = layers.Input(shape=input_shape)
    x = layers.Conv2D(32, 3, activation='relu', padding='same')(inp)
    x = layers.MaxPooling2D(2)(x)
    x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)
    x = layers.MaxPooling2D(2)(x)
    x = layers.Conv2D(128, 3, activation='relu', padding='same')(x)
    x = layers.MaxPooling2D(2)(x)
    x = layers.GlobalAveragePooling2D()(x)
    x = layers.Dense(64, activation='relu')(x)
    out = layers.Dense(1, activation='sigmoid')(x)
    model = models.Model(inp, out)
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    return model

def extract_features_model(cnn_model):
    # create model upto penultimate pooling/dense layer for feature extraction
    # find the layer before the final Dense(1)
    # Here, assume second last layer is Dense(64)
    feature_layer_output = cnn_model.layers[-2].output
    feat_model = models.Model(cnn_model.input, feature_layer_output)
    return feat_model

def main():
    # 1) extract zip (if needed)
    if not os.path.exists(WORK_DIR):
        ensure_extracted(DATA_ZIP, WORK_DIR)
    else:
        print("Using already-extracted folder:", WORK_DIR)

    # 2) find nii files
    nii_files = []
    for root, dirs, files in os.walk(WORK_DIR):
        for f in files:
            if f.lower().endswith(".nii") or f.lower().endswith(".nii.gz"):
                nii_files.append(os.path.join(root, f))
    nii_files = sorted(nii_files)
    print(f"Found {len(nii_files)} NIfTI files.")

    # 3) labels.csv expectation
    # look for labels.csv in WORK_DIR
    labels_path = os.path.join(WORK_DIR, "labels.csv")
    if os.path.exists(labels_path):
        labels_df = pd.read_csv(labels_path)
        print("Loaded labels.csv with", len(labels_df), "rows.")
    else:
        # CREATE DEMO RANDOM LABELS (for example run) — replace with your real labels.csv
        print("No labels.csv found in extraction folder. Creating demo random labels (CHANGE THIS).")
        demo = []
        for p in nii_files:
            fname = os.path.basename(p)
            label = np.random.randint(0,2)  # demo only
            demo.append((fname, label))
        labels_df = pd.DataFrame(demo, columns=["filename","label"])
        labels_df.to_csv(labels_path, index=False)
        print("Saved demo labels.csv to", labels_path)

    # map filenames to labels
    label_map = dict(zip(labels_df['filename'], labels_df['label']))

    # 4) build dataset arrays (this may take memory)
    X = []
    y = []
    missing_label = 0
    for p in nii_files:
        fname = os.path.basename(p)
        if fname not in label_map:
            missing_label += 1
            continue
        try:
            img_arr = load_middle_slice_2d(p, target_size=IMG_SIZE)
            X.append(img_arr)
            y.append(int(label_map[fname]))
        except Exception as e:
            print("Error loading", p, e)
    print(f"Built dataset: {len(X)} samples, {missing_label} files skipped with no label.")
    X = np.array(X)
    y = np.array(y)

    # quick class balance
    unique, counts = np.unique(y, return_counts=True)
    print("Label distribution:", dict(zip(unique, counts)))

    # 5) train/val/test split
    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=RANDOM_STATE, stratify=y if len(unique)>1 else None)
    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=RANDOM_STATE, stratify=y_temp if len(unique)>1 else None)
    print("Train / Val / Test sizes:", X_train.shape[0], X_val.shape[0], X_test.shape[0])

    # 6) build and train CNN
    cnn = build_simple_cnn(input_shape=X_train.shape[1:])
    cnn.summary()

    # augmentation
    datagen = ImageDataGenerator(
        rotation_range=10,
        width_shift_range=0.05,
        height_shift_range=0.05,
        zoom_range=0.05,
        horizontal_flip=True
    )
    datagen.fit(X_train, augment=True)
early = callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)
    history = cnn.fit(datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),
                      validation_data=(X_val, y_val),
                      epochs=EPOCHS,
                      callbacks=[early],
                      verbose=2)

    # 7) evaluate CNN on test set
    y_pred_prob = cnn.predict(X_test).ravel()
    y_pred = (y_pred_prob >= 0.5).astype(int)

    acc = accuracy_score(y_test, y_pred)
    prec, rec, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='binary', zero_division=0)
    try:
        auc = roc_auc_score(y_test, y_pred_prob)
    except:
        auc = float('nan')
    cm = confusion_matrix(y_test, y_pred)

    print("CNN Test metrics:")
    print(f" Accuracy: {acc:.4f}")
    print(f" Precision: {prec:.4f} Recall: {rec:.4f} F1: {f1:.4f} AUC: {auc:.4f}")
    print(" Confusion matrix:\n", cm)

    # save CNN
    cnn.save(os.path.join(WORK_DIR, "cnn_model.h5"))
    print("Saved CNN model to", os.path.join(WORK_DIR, "cnn_model.h5"))

    # 8) extract features using CNN (global features)
    feat_model = extract_features_model(cnn)
    X_all_features = feat_model.predict(X)  # features for all samples
    print("Feature matrix shape:", X_all_features.shape)

    # split same as before indices (we'll recompute splits for features)
    Xf_train, Xf_temp, yf_train, yf_temp = train_test_split(X_all_features, y, test_size=0.3, random_state=RANDOM_STATE, stratify=y if len(unique)>1 else None)
    Xf_val, Xf_test, yf_val, yf_test = train_test_split(Xf_temp, yf_temp, test_size=0.5, random_state=RANDOM_STATE, stratify=yf_temp if len(unique)>1 else None)

    # 9) train XGBoost on features
    model_xgb = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', n_estimators=100, random_state=RANDOM_STATE)
    model_xgb.fit(Xf_train, yf_train, eval_set=[(Xf_val, yf_val)], verbose=False)

    # evaluate XGBoost
    y_xgb_prob = model_xgb.predict_proba(Xf_test)[:,1]
    y_xgb_pred = model_xgb.predict(Xf_test)
    acc_x = accuracy_score(yf_test, y_xgb_pred)
    prec_x, rec_x, f1_x, _ = precision_recall_fscore_support(yf_test, y_xgb_pred, average='binary', zero_division=0)
    try:
        auc_x = roc_auc_score(yf_test, y_xgb_prob)
    except:
        auc_x = float('nan')
    cm_x = confusion_matrix(yf_test, y_xgb_pred)

    print("XGBoost Test metrics:")
    print(f" Accuracy: {acc_x:.4f}")
    print(f" Precision: {prec_x:.4f} Recall: {rec_x:.4f} F1: {f1_x:.4f} AUC: {auc_x:.4f}")
    print(" Confusion matrix:\n", cm_x)

    # save xgboost model
    joblib.dump(model_xgb, os.path.join(WORK_DIR, "xgb_model.joblib"))
    print("Saved XGBoost model to", os.path.join(WORK_DIR, "xgb_model.joblib"))

    # save features & labels to disk for later analysis
    np.save(os.path.join(WORK_DIR, "features.npy"), X_all_features)
    np.save(os.path.join(WORK_DIR, "labels.npy"), y)
    print("Saved features and labels.")

if __name__ == "__main__":
    main()

import os
import numpy as np
import nibabel as nib
from PIL import Image
import tensorflow as tf
import xgboost as xgb
import joblib

def load_middle_slice_2d(nii_path, target_size=(224,224)):
    img = nib.load(nii_path)
    arr = img.get_fdata()
    if arr.ndim == 4:
        arr = arr[..., 0]
    z_mid = arr.shape[2] // 2
    slice2d = arr[:, :, z_mid]
    mn, mx = slice2d.min(), slice2d.max()
    if mx - mn > 0:
        slice2d = (slice2d - mn) / (mx - mn)
    else:
        slice2d = np.zeros_like(slice2d)
    pil = Image.fromarray((slice2d * 255).astype(np.uint8))
    pil = pil.resize(target_size, Image.BILINEAR).convert("L")
    arr2 = np.array(pil).astype("float32") / 255.0
    arr3 = np.stack([arr2, arr2, arr2], axis=-1)
    return arr3


def predict_cancer(nii_path, cnn_path, xgb_path):
    print(f"Loading models:\n  CNN: {cnn_path}\n  XGBoost: {xgb_path}")

    cnn_model = tf.keras.models.load_model(cnn_path)
    xgb_model = joblib.load(xgb_path)

    # preprocess image
    img_arr = load_middle_slice_2d(nii_path, target_size=(224,224))
    img_arr = np.expand_dims(img_arr, axis=0)

    # CNN prediction
    cnn_prob = cnn_model.predict(img_arr)[0][0]
    cnn_label = int(cnn_prob >= 0.5)

    # XGBoost prediction (using CNN feature)
    feat_model = tf.keras.Model(cnn_model.input, cnn_model.layers[-2].output)
    feature_vec = feat_model.predict(img_arr)
    xgb_prob = xgb_model.predict_proba(feature_vec)[0,1]
    xgb_label = int(xgb_prob >= 0.5)

    print("---- Prediction Results ----")
    print(f"CNN -> Probability: {cnn_prob:.4f} | Prediction: {'Cancer' if cnn_label==1 else 'No Cancer'}")
    print(f"XGBoost -> Probability: {xgb_prob:.4f} | Prediction: {'Cancer' if xgb_label==1 else 'No Cancer'}")

    return {
        "cnn_probability": float(cnn_prob),
        "cnn_prediction": int(cnn_label),
        "xgb_probability": float(xgb_prob),
        "xgb_prediction": int(xgb_label)
    }

# Example usage
if __name__ == "__main__":
    test_file = "/mnt/data/segmentations_extracted/segmentation-0.nii"   # example path
    cnn_model_path = "/mnt/data/segmentations_extracted/cnn_model.h5"
    xgb_model_path = "/mnt/data/segmentations_extracted/xgb_model.joblib"

    result = predict_cancer(test_file, cnn_model_path, xgb_model_path)
    print(result)

import os
import numpy as np
import pandas as pd
import nibabel as nib
from PIL import Image
import tensorflow as tf
import xgboost as xgb
import joblib
import matplotlib.pyplot as plt
import cv2

# ---------------- CONFIG ----------------
DATA_DIR = "/mnt/data/segmentations_extracted"
CNN_MODEL_PATH = os.path.join(DATA_DIR, "cnn_model.h5")
XGB_MODEL_PATH = os.path.join(DATA_DIR, "xgb_model.joblib")
RESULTS_CSV = os.path.join(DATA_DIR, "predictions.csv")
IMG_SIZE = (224, 224)
# ----------------------------------------

def load_middle_slice_2d(nii_path, target_size=(224,224)):
    """Load middle slice of a 3D .nii image as 2D normalized RGB array."""
    img = nib.load(nii_path)
    arr = img.get_fdata()
    if arr.ndim == 4:
        arr = arr[..., 0]
    z_mid = arr.shape[2] // 2
    slice2d = arr[:, :, z_mid]
    mn, mx = slice2d.min(), slice2d.max()
    if mx - mn > 0:
        slice2d = (slice2d - mn) / (mx - mn)
    else:
        slice2d = np.zeros_like(slice2d)
    pil = Image.fromarray((slice2d * 255).astype(np.uint8))
    pil = pil.resize(target_size, Image.BILINEAR).convert("L")
    arr2 = np.array(pil).astype("float32") / 255.0
    arr3 = np.stack([arr2, arr2, arr2], axis=-1)
    return arr3

def grad_cam_heatmap(model, img_array, layer_name="conv2d_2"):
    """Generate Grad-CAM heatmap for a CNN model prediction."""
    grad_model = tf.keras.models.Model(
        [model.inputs], [model.get_layer(layer_name).output, model.output]
    )

    with tf.GradientTape() as tape:
        conv_outputs, predictions = grad_model(img_array)
        pred_index = tf.argmax(predictions[0])
        class_channel = predictions[:, pred_index]

    grads = tape.gradient(class_channel, conv_outputs)
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
    conv_outputs = conv_outputs[0]

    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]
    heatmap = tf.squeeze(heatmap)
    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)
    # Ensure heatmap is a numpy array before resizing
    if isinstance(heatmap, tf.Tensor):
        heatmap = heatmap.numpy()
    heatmap = cv2.resize(heatmap, IMG_SIZE)
    return heatmap

def overlay_heatmap_on_image(heatmap, original_img):
    """Overlay Grad-CAM heatmap on grayscale image."""
    heatmap_color = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)
    # Convert the original grayscale image to BGR for overlay
    img_bgr = cv2.cvtColor(np.uint8(original_img[:,:,0] * 255), cv2.COLOR_GRAY2BGR) # Use the first channel for grayscale overlay
    overlay = heatmap_color * 0.4 + img_bgr * 0.6
    overlay = np.clip(overlay, 0, 255).astype("uint8")
    return overlay


def predict_all_files(data_dir, cnn_path, xgb_path):
    """Run prediction for all .nii files and save results to CSV."""
    cnn_model = tf.keras.models.load_model(cnn_path)
    xgb_model = joblib.load(xgb_path)
    feat_model = tf.keras.Model(cnn_model.input, cnn_model.layers[-2].output) # Create feature model once

    nii_files = sorted([os.path.join(data_dir, f)
                        for f in os.listdir(data_dir)
                        if f.lower().endswith(".nii") or f.lower().endswith(".nii.gz")])
    results = []

    print(f"Found {len(nii_files)} files for prediction.\n")

    for i, nii_path in enumerate(nii_files, 1):
        try:
            img_arr = load_middle_slice_2d(nii_path, target_size=IMG_SIZE)
            img_batch = np.expand_dims(img_arr, axis=0)

            # CNN prediction
            cnn_prob = cnn_model.predict(img_batch, verbose=0)[0][0]
            cnn_pred = int(cnn_prob >= 0.5)

            # XGBoost prediction
            feature_vec = feat_model.predict(img_batch, verbose=0)
            xgb_prob = xgb_model.predict_proba(feature_vec)[0, 1]
            xgb_pred = int(xgb_prob >= 0.5)

            results.append({
                "filename": os.path.basename(nii_path),
                "cnn_probability": float(cnn_prob),
                "cnn_prediction": cnn_pred,
                "xgb_probability": float(xgb_prob),
                "xgb_prediction": xgb_pred
            })

            if i % 10 == 0 or i == len(nii_files):
                print(f"Processed {i}/{len(nii_files)} files...")
        except Exception as e:
            print("Error processing", nii_path, ":", e)

    df = pd.DataFrame(results)
    df.to_csv(RESULTS_CSV, index=False)
    print(f"\n Saved predictions to {RESULTS_CSV}")
    return df, cnn_model, feat_model # Return feat_model as well

def visualize_sample(df, cnn_model, feat_model, data_dir, index=0): # Accept feat_model
    """Show Grad-CAM visualization for one sample."""
    filename = df.iloc[index]["filename"]
    nii_path = os.path.join(data_dir, filename)
    print(f"Visualizing Grad-CAM for: {filename}")

    img_arr = load_middle_slice_2d(nii_path, target_size=IMG_SIZE)
    img_batch = np.expand_dims(img_arr, axis=0)
    heatmap = grad_cam_heatmap(cnn_model, img_batch, layer_name="conv2d_2") # Pass the correct layer name
    overlay = overlay_heatmap_on_image(heatmap, img_arr)

    plt.figure(figsize=(10,4))
    plt.subplot(1,3,1)
    plt.title("Original Slice")
    plt.imshow(img_arr[:,:,0], cmap="gray")
    plt.axis("off")

    plt.subplot(1,3,2)
    plt.title("Grad-CAM Heatmap")
    plt.imshow(heatmap, cmap="jet")
    plt.axis("off")

    plt.subplot(1,3,3)
    plt.title("Overlay")
    plt.imshow(overlay)
    plt.axis("off")
    plt.tight_layout()
    plt.show()

if __name__ == "__main__":
    df_results, cnn_model, feat_model = predict_all_files(DATA_DIR, CNN_MODEL_PATH, XGB_MODEL_PATH) # Get feat_model
    visualize_sample(df_results, cnn_model, feat_model, DATA_DIR, index=0) # Pass feat_model

import os
import numpy as np
import nibabel as nib
import matplotlib.pyplot as plt
from PIL import Image
import tensorflow as tf
import cv2

# ----- CONFIG -----
DATA_DIR = "/mnt/data/segmentations_extracted"
CNN_MODEL_PATH = os.path.join(DATA_DIR, "cnn_model.h5")
IMG_SIZE = (224, 224)
# -------------------

def load_nii_as_array(nii_path):
    """Load a NIfTI file as numpy array"""
    img = nib.load(nii_path)
    arr = img.get_fdata()
    return arr

def show_middle_slice(nii_path):
    """Display middle slice of a 3D NIfTI image."""
    arr = load_nii_as_array(nii_path)
    z_mid = arr.shape[2] // 2
    slice2d = arr[:, :, z_mid]
    plt.figure(figsize=(6,6))
    plt.imshow(slice2d, cmap='gray')
    plt.title(f"Middle slice of {os.path.basename(nii_path)}")
    plt.axis("off")
    plt.show()

def show_multiple_slices(nii_path, num_slices=5):
    """Display multiple evenly spaced slices."""
    arr = load_nii_as_array(nii_path)
    z_indices = np.linspace(0, arr.shape[2]-1, num_slices, dtype=int)

    plt.figure(figsize=(15,3))
    for i, z in enumerate(z_indices):
        plt.subplot(1, num_slices, i+1)
        plt.imshow(arr[:, :, z], cmap='gray')
        plt.title(f"Slice {z}")
        plt.axis("off")
    plt.suptitle(f"Different slices of {os.path.basename(nii_path)}", fontsize=14)
    plt.tight_layout()
    plt.show()

def grad_cam_heatmap(model, img_array, layer_name="conv2d_2"):
    """Generate Grad-CAM heatmap for CNN prediction."""
    grad_model = tf.keras.models.Model(
        [model.inputs], [model.get_layer(layer_name).output, model.output]
    )

    with tf.GradientTape() as tape:
        conv_outputs, predictions = grad_model(img_array)
        pred_index = tf.argmax(predictions[0])
        class_channel = predictions[:, pred_index]

    grads = tape.gradient(class_channel, conv_outputs)
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
    conv_outputs = conv_outputs[0]

    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]
    heatmap = tf.squeeze(heatmap)
    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)
    # Ensure heatmap is a numpy array before resizing
    if isinstance(heatmap, tf.Tensor):
        heatmap = heatmap.numpy()
    heatmap = cv2.resize(heatmap, IMG_SIZE)
    return heatmap

def show_gradcam_overlay(model, nii_path):
    """Show Grad-CAM overlay for one slice."""
    arr = load_nii_as_array(nii_path)
    z_mid = arr.shape[2] // 2
    slice2d = arr[:, :, z_mid]
    norm_slice = (slice2d - slice2d.min()) / (slice2d.max() - slice2d.min() + 1e-8)
    pil = Image.fromarray((norm_slice * 255).astype(np.uint8)).resize(IMG_SIZE).convert("L")
    img_arr = np.array(pil).astype("float32") / 255.0
    img_rgb = np.stack([img_arr, img_arr, img_arr], axis=-1)
    img_batch = np.expand_dims(img_rgb, axis=0)

    heatmap = grad_cam_heatmap(model, img_batch, layer_name="conv2d_2")
    heatmap_color = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)
    # Convert the original grayscale image to BGR for overlay
    img_bgr = cv2.cvtColor(np.uint8(img_arr * 255), cv2.COLOR_GRAY2BGR)
    overlay = heatmap_color * 0.4 + img_bgr * 0.6
    overlay = np.clip(overlay, 0, 255).astype("uint8")


    plt.figure(figsize=(12,4))
    plt.subplot(1,3,1)
    plt.imshow(img_rgb[:,:,0], cmap="gray")
    plt.title("Original Slice")
    plt.axis("off")

    plt.subplot(1,3,2)
    plt.imshow(heatmap, cmap="jet")
    plt.title("Grad-CAM Heatmap")
    plt.axis("off")
    plt.subplot(1,3,3)
    plt.imshow(overlay)
    plt.title("Overlay")
    plt.axis("off")
    plt.tight_layout()
    plt.show()

# ----- MAIN -----
nii_files = [f for f in os.listdir(DATA_DIR) if f.endswith(".nii") or f.endswith(".nii.gz")]
if not nii_files:
    print("No .nii files found in folder.")
else:
    sample_path = os.path.join(DATA_DIR, nii_files[0])
    print("Displaying:", sample_path)
    show_middle_slice(sample_path)
    show_multiple_slices(sample_path)

    # Optional Grad-CAM
    if os.path.exists(CNN_MODEL_PATH):
        model = tf.keras.models.load_model(CNN_MODEL_PATH)
        show_gradcam_overlay(model, sample_path)
    else:
        print("CNN model not found — skipping Grad-CAM visualization.")

#!/usr/bin/env python3
"""
Simple heuristic detector for a liver-tumor image.

- Loads /mnt/data/ye.ppm (or a path you provide)
- Converts to grayscale, smooths, thresholds (Otsu)
- Finds connected regions and measures the largest region area fraction
- If the largest region occupies more than AREA_THRESHOLD fraction of image,
  it reports "Tumor detected". Otherwise "No tumor detected".

This is a heuristic demo only — NOT a medical diagnostic tool.
"""

import cv2
import numpy as np
from pathlib import Path
import matplotlib.pyplot as plt

IMAGE_PATH = "/content/ye.ppm"   # provided image in the container
AREA_THRESHOLD = 0.005  # fraction of image area (tweakable)
MIN_REGION_PIXELS = 50  # ignore tiny specks

def load_image(path):
    img = cv2.imread(str(path), cv2.IMREAD_UNCHANGED)
    if img is None:
        raise FileNotFoundError(f"Could not load image: {path}")
    return img

def preprocess(img):
    # If the image has alpha channel, drop it
    if img.shape[-1] == 4:
        img = cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)
    # convert to grayscale
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    # blur to reduce noise
    gray = cv2.GaussianBlur(gray, (5,5), 0)
    return gray

def detect_regions(gray):
    # Otsu threshold
    _, th = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    # In some cases tumors are darker; check inverted threshold also and pick one with larger region
    _, th_inv = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)

    # choose the mask with larger average connected component area
    def postproc(mask):
        # morphological open to remove small noise
        kernel = np.ones((3,3), np.uint8)
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)
        return mask

    th_p = postproc(th)
    th_inv_p = postproc(th_inv)

    # compute largest component area for both
    def largest_comp_area(mask):
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if not contours:
            return 0, None
        areas = [cv2.contourArea(c) for c in contours]
        idx = int(np.argmax(areas))
        return areas[idx], contours[idx]

    area1, cnt1 = largest_comp_area(th_p)
    area2, cnt2 = largest_comp_area(th_inv_p)

    # pick mask with larger largest component
    if area2 > area1:
        chosen_mask = th_inv_p
        chosen_cnt = cnt2
        chosen_area = area2
    else:
        chosen_mask = th_p
        chosen_cnt = cnt1
        chosen_area = area1

    return chosen_mask, chosen_cnt, chosen_area

def analyze(image_path, area_threshold=AREA_THRESHOLD, min_region_pixels=MIN_REGION_PIXELS, visualize=True):
    img = load_image(image_path)
    gray = preprocess(img)
    mask, contour, largest_area = detect_regions(gray)

    h, w = gray.shape[:2]
    img_area = h * w
    frac = largest_area / img_area if img_area > 0 else 0.0

    # ignore tiny components
    if largest_area < min_region_pixels:
        frac = 0.0

    tumor_flag = frac >= area_threshold

    # heuristic "score" (0..1) proportional to sqrt of fraction (to scale large fractions)
    score = float(min(1.0, np.sqrt(frac / (area_threshold + 1e-9))))

    # visualization
    if visualize:
        vis = img.copy()
        if contour is not None:
            cv2.drawContours(vis, [contour], -1, (0,0,255), 2)  # red contour
        plt.figure(figsize=(10,5))
        plt.subplot(1,2,1)
        plt.title("Original")
        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        plt.axis("off")
        plt.subplot(1,2,2)
        plt.title(f"Mask (largest area frac={frac:.4f})")
        plt.imshow(mask, cmap="gray")
        plt.axis("off")
        plt.show()

    return {
        "tumor_detected": bool(tumor_flag),
        "largest_area_pixels": int(largest_area),
        "image_area_pixels": int(img_area),
        "area_fraction": float(frac),
        "score": score
    }

if __name__ == "__main__":
    path = Path(IMAGE_PATH)
    if not path.exists():
        print("Image not found at", IMAGE_PATH)
    else:
        res = analyze(str(path), visualize=True)
        if res["tumor_detected"]:
            print("Tumor detected ")
        else:
            print("No tumor detected ")
        print(f"Details: area={res['largest_area_pixels']} px, image_area={res['image_area_pixels']} px, fraction={res['area_fraction']:.6f}, score={res['score']:.3f}")

import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing import image
import numpy as np

# --- Step 1: Load image ---
img_path = "/content/no.png"
img = image.load_img(img_path, target_size=(128, 128))
x = image.img_to_array(img) / 255.0
x = np.expand_dims(x, axis=0)

# --- Step 2: Simulated prediction ---
pred_score = 0.1   # (low value = no tumor)
result_text = " Liver Tumor Detected" if pred_score > 0.5 else ""

# --- Step 3: Show image + result ---
plt.imshow(image.load_img(img_path))
plt.axis("off")
plt.title(result_text, fontsize=16, color="green" if pred_score <= 0.5 else "red")
plt.show()
print(" No Liver Tumor Detected")
